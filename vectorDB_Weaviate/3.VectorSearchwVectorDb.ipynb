{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\behna\\Desktop\\venv\\vector_db\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import requests\n",
    "\n",
    "# vectorDB\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "# dl\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:12<00:00, 18.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18895923  1.0901791   0.8831661  ...  1.0861775  -1.2602544\n",
      "  1.6406289 ]\n"
     ]
    }
   ],
   "source": [
    "# Load Hugging Face model and tokenizer\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def vectorize_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Take the mean of the token embeddings as the sentence embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WCD_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WCD_API_KEY\")\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    auth_client_secret=weaviate.auth.AuthApiKey(api_key=WEAVIATE_API_KEY)\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Example text to vectorize\n",
    "    text = \"Weaviate is a great tool for managing vectors!\"\n",
    "    vector = vectorize_text(text)\n",
    "    print(vector)\n",
    "\n",
    "finally:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the schema.\n"
     ]
    }
   ],
   "source": [
    "# setting up collection\n",
    "# resetting the schema. CAUTION: This will delete your collection \n",
    "# if client.schema.exists(\"MyFirstCollection\"):\n",
    "#      client.schema.delete_class(\"MyFirstCollection\")\n",
    "schema = {\n",
    "    \"class\": \"MyCollection\",\n",
    "    \"description\": \"collection of texts converted to vectors Deeplearing.ai short course\",\n",
    "    \"vectorizer\": \"none\",\n",
    "    \"vectorIndexConfig\": {\n",
    "        \"distance\": \"cosine\" # let's use cosine distance\n",
    "    },\n",
    "}\n",
    "\n",
    "client.schema.create_class(schema)\n",
    "\n",
    "print(\"Successfully created the schema.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "   {\n",
    "      \"title\": \"First Object\",\n",
    "      \"foo\": 99, \n",
    "      \"vector\": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "   },\n",
    "   {\n",
    "      \"title\": \"Second Object\",\n",
    "      \"foo\": 77, \n",
    "      \"vector\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "   },\n",
    "   {\n",
    "      \"title\": \"Third Object\",\n",
    "      \"foo\": 55, \n",
    "      \"vector\": [0.3, 0.1, -0.1, -0.3, -0.5, -0.7]\n",
    "   },\n",
    "   {\n",
    "      \"title\": \"Fourth Object\",\n",
    "      \"foo\": 33, \n",
    "      \"vector\": [0.4, 0.41, 0.42, 0.43, 0.44, 0.45]\n",
    "   },\n",
    "   {\n",
    "      \"title\": \"Fifth Object\",\n",
    "      \"foo\": 11,\n",
    "      \"vector\": [0.5, 0.5, 0, 0, 0, 0]\n",
    "   },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batch.configure(batch_size=10)  # Configure batch\n",
    "\n",
    "# Batch import all objects\n",
    "# yes batch is an overkill for 5 objects, but it is recommended for large volumes of data\n",
    "with client.batch as batch:\n",
    "  for item in data:\n",
    "\n",
    "      properties = {\n",
    "         \"title\": item[\"title\"],\n",
    "         \"foo\": item[\"foo\"],\n",
    "      }\n",
    "\n",
    "      # the call that performs data insert\n",
    "      client.batch.add_data_object(\n",
    "         class_name=\"MyCollection\",\n",
    "         data_object=properties,\n",
    "         vector=item[\"vector\"] # your vector embeddings go here\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Aggregate': {'MyCollection': [{'meta': {'count': 5}}]}}}\n"
     ]
    }
   ],
   "source": [
    "# Check number of objects\n",
    "response = (\n",
    "    client.query\n",
    "    .aggregate(\"MyCollection\")\n",
    "    .with_meta_count()\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Vector DB: Vector (embedding) Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"title\": \"Second Object\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Fourth Object\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response = (\n",
    "    client.query\n",
    "    .get(\"MyCollection\", [\"title\"])\n",
    "    .with_near_vector({\n",
    "        \"vector\": [-0.012, 0.021, -0.23, -0.42, 0.5, 0.5]\n",
    "    })\n",
    "    .with_limit(2) # limit the output to only 2\n",
    "    .do()\n",
    ")\n",
    "\n",
    "result = response[\"data\"][\"Get\"][\"MyCollection\"]\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"_additional\": {\n",
      "      \"distance\": 0.6506307,\n",
      "      \"id\": \"a1fa2f15-2666-4dd7-b207-b98329920e63\",\n",
      "      \"vector\": [\n",
      "        0.2,\n",
      "        0.3,\n",
      "        0.4,\n",
      "        0.5,\n",
      "        0.6,\n",
      "        0.7\n",
      "      ]\n",
      "    },\n",
      "    \"title\": \"Second Object\"\n",
      "  },\n",
      "  {\n",
      "    \"_additional\": {\n",
      "      \"distance\": 0.8072029,\n",
      "      \"id\": \"cb0e550e-fcc6-4f61-9e94-18b8cd7015fb\",\n",
      "      \"vector\": [\n",
      "        0.4,\n",
      "        0.41,\n",
      "        0.42,\n",
      "        0.43,\n",
      "        0.44,\n",
      "        0.45\n",
      "      ]\n",
      "    },\n",
      "    \"title\": \"Fourth Object\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response = (\n",
    "    client.query\n",
    "    .get(\"MyCollection\", [\"title\"])\n",
    "    .with_near_vector({\n",
    "        \"vector\": [-0.012, 0.021, -0.23, -0.42, 0.5, 0.5]\n",
    "    })\n",
    "    .with_limit(2) # limit the output to only 2\n",
    "    .with_additional([\"distance\", \"vector, id\"])\n",
    "    .do()\n",
    ")\n",
    "\n",
    "result = response[\"data\"][\"Get\"][\"MyCollection\"]\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
